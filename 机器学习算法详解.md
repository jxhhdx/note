#  机器学习算法详解

## 机器学习简介

### 学习目标

- 了解和机器学习相关的概念
- 了解机器学习的实质
- 了解常见损失函数
- 了解经验风险与结构风险

### 课程纲要

- 机器学习的几个概念

- 机器学学习的实质

- 机器学习方法的三要素

- 经验风险与结构风险

## 机器学习的基本概念

**有监督学习**：有结果的训练

**输入空间**：所有输入可能取值的集合

**输出空间**：所有输出可能取值的集合

**特征**：就是属性。

**特征向量**：由多个特征组成的集合

**特征空间**：由多个特征向量组成的集合

**假设空间**：由输入空间到输出空间的映射的集合（问题所有假设组成的空间）(针对每一个可能的输入都能找到一个映射与输出空间的某一个结果映射)

## 机器学习的三要素

- 机器学习方法通常都是由**模型**、**策略**和**算法**三部分构成：方法=模型+策略+算法
  - 模型：输入空间到输出空间的映射关系（确定学习范围），学习过程就是从假设空间中找到适合当前数据的假设。分析当前需要解决的问题，确定模型。
    ![image-20200101170118850](\public\image\jiqi01.png)
  
  - 策略：从假设空间众多假设中选择到最优的模型的学习标准或规则（确定学习规则）
  
    要从假设空间中选择一个合适的模型出来，需要解决一下问题
  
    - 评估某某模型对单个训练样本的效果
    - 评估某某模型对训练集的整体效果
    - 评估某个模型对包括训练集、预测集在内的所有数据的整体效果
  
    定义几个指标用来衡量上述问题：
  
    - **损失函数**：0-1损失函数、平方损失函数、绝对损失函数、对数损失函数等
  
    - **风险函数**：经验风险、期望风险、结构风险。
  
    基本策略
  
    - 经验风险最小
    - 结构风险最小
  
  - 算法：学习模型的具体的计算方法，通常是求解最优化问题。（按规则在范围内学习）

#### 损失函数

- 用来衡量预测结果和真实结果之间的差距，其值越小，代表预测结果和真实结果越一致。通常是一个非负实值函数。通过各种方式缩小损失函数的过程称为**优化**。损失函数记做**L(Y,f(X))**。

#####  **0-1损失函数(0-1 LF)**
- 预测值和实际值精确相等则"没有损失"为0，则意味着"完全损失"，为1预测和实际值精确相等有些过于严格，可以采用两者的差小于某个阈值的方式。
  $$
  L(Y,f(X)) = \left\{
  \begin{aligned}
  1,Y \not= f(X) \\
  0,Y = f(X) \\
  \end{aligned}
  \right.
  $$

- 以上有点过于严格，可以放宽一点。

$$
L(Y,f(X)) = \left\{
  \begin{aligned}
  1,|Y - f(X)| \geq T \\
  0,|Y = f(X)| < T \\
  \end{aligned}
  \right.
$$

- 对于相同的预测结果，两个损失函数严格程度不同。设T=0.5则有

- | Y    | f(X) | L    | L'   |
  | ---- | ---- | ---- | ---- |
  | 0    | 0.3  | 1    | 0    |
  | 1    | 0.8  | 1    | 0    |
  | 1    | 1.2  | 1    | 0    |
  | 0    | 0    | 0    | 0    |

##### 绝对值损失函数（Absolute LF）

  - 预测结果与真实结果差的绝对值。简单易懂，但是计算不方便。

$$
L(Y,f(X)) = |Y - f(X)|
$$

##### 平方损失函数（Quadratic LF ）

- 预测结果与真实结果差的平方。

$$
L(Y,f(X)) = （Y - f(X)）^2
$$

  平方损失函数优势有：

- 每个样本的误差都是正的，累加不会被抵消
- 平方对于大误差的惩罚大于小误差
- 数学计算简单、友好，导数为一次函数

| Y    | f(x) | A LF | S LF |
| ---- | ---- | ---- | ---- |
| 0    | 0.3  | 0.3  | 0.09 |
| 1    | 0.8  | 0.8  | 0.04 |
| 1    | 1.2  | 1.2  | 0.04 |
| 0    | 0    | 0    | 0    |

##### 对数损失函数（Logarithmic LF）

- 或**对数似然损失函数（log-likehood loss function）**:对数函数具有单调性，在求最优化问题时，结果与原始目标一致。可将乘法转化为加法，简化计算：
  $$
  L(Y,P(Y|X)) = -logP(Y|X)
  $$
  

##### 指数损失函数（Exponential LF）

- 单调性、非负性的优良性质，使得越接近正确结果误差越小

$$
L(Y,f(x)) = e^{-Y*f(x)}
$$

##### 折叶损失函数（Hinge LF）

- 对于判定边界附近的点的惩罚力度较高，常见于SVM
  $$
  L(f(x)) = max(0,1 - f(x))
  $$
  

#### 经验风险 VS 风险函数

**经验风险**：损失函数度量了单个样本的预测结果，要想衡量整个训练集的预测与真实值的差异，将整个训练集所有记录均进行一次预测，求取损失函数，将所有值累加，即为经验风险。经验风险越说明模型f（X）对训练集的拟合度越好。

公式为：
$$
R_{emp}(f) = \frac{1}{N}\sum_{i=1}^N L(Y,f(x))
$$
**风险函数**：又称期望损失、期望风险。所有数据集（包括训练集和预测集，遵循联合分布P(X,Y)）的损失函数的期望值。公式为：
$$
R_{emp}(f) = \iint L(Y,f(x))P(x,y)dxdy
$$
**经验风险 VS 期望风险：**

- 七五风险是模型对全局（所有数据集）的效果；经验是模型对局部（训练集）的效果
- 期望风险往往无法计算，即联合分布P(X,Y)通常是未知的；经验风险可以计算
- 当训练集足够大时，经验风险可以替代期望风险，即局部最优代替全局最优。
